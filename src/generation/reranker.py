import json
from langchain_core.runnables import RunnableLambda
from generation.llm import get_llm


def _rerank_logic(inputs: dict):
    question = inputs["question"]
    docs = inputs["retrieval_results"]

    llm = get_llm()

    prompt = (
        "ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì§ˆë¬¸ê³¼ì˜ ê´€ë ¨ì„± ê¸°ì¤€ìœ¼ë¡œ 0~5ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.\n"
        "JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n\n"
        f"ì§ˆë¬¸: {question}\n\n"
    )

    for d in docs:
        prompt += (
            f"chunk_id={d['chunk_id']} | section={d['meta'].get('section')}\n"
            f"{d['text']}\n\n"
        )

    try:
        resp = llm.invoke(prompt)
        scores = json.loads(resp.content)
        score_map = {s["chunk_id"]: s["score"] for s in scores}
    except Exception:
        score_map = {}

    reranked = sorted(
        docs,
        key=lambda d: score_map.get(d["chunk_id"], 0),
        reverse=True,
    )

    return {
        "question": question,
        "rerank_scores": score_map,  # ğŸ”¥ LangSmithì— ë‚¨ìŒ
        "top_docs": reranked[:5],
    }


reranker = RunnableLambda(_rerank_logic).with_config(
    run_name="LLMReranker",
    tags=["generation", "rerank"],
)
